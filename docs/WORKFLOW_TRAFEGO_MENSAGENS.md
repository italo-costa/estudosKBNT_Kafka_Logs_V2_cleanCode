# ğŸ”„ Workflow de TrÃ¡fego de Mensagens - Sistema KBNT Kafka

## ğŸ“‹ VisÃ£o Geral do Fluxo

O sistema implementa um pipeline completo de processamento de logs com arquitetura orientada a eventos, utilizando Apache Kafka como backbone de mensageria.

## ğŸš€ Etapas Detalhadas do Workflow

### **Etapa 1: GeraÃ§Ã£o e Captura de Logs** 
```
[AplicaÃ§Ã£o] â†’ [Log Producer Service] â†’ [ValidaÃ§Ã£o] â†’ [SerializaÃ§Ã£o]
```

**ğŸ› ï¸ Tecnologias:**
- **Spring Boot 3.2**: Framework principal do Producer Service
- **Logback/SLF4J**: Sistema de logging estruturado
- **Jackson**: SerializaÃ§Ã£o JSON de mensagens
- **Spring Validation**: ValidaÃ§Ã£o de dados de entrada

**ğŸ“ Processo:**
1. **AplicaÃ§Ã£o gera evento** (erro, transaÃ§Ã£o, auditoria, etc.)
2. **Producer Service recebe via REST API** (`POST /api/logs`)
3. **ValidaÃ§Ã£o de payload** (campos obrigatÃ³rios, formato)
4. **Enriquecimento de dados** (timestamp, correlationId, metadados)
5. **SerializaÃ§Ã£o para JSON** estruturado

**ğŸ’¡ Exemplo de Payload:**
```json
{
  "level": "ERROR",
  "message": "Database connection timeout",
  "service": "payment-service",
  "timestamp": "2025-08-29T14:30:45.123Z",
  "correlationId": "uuid-12345",
  "metadata": {
    "userId": "user123",
    "transactionId": "tx456"
  }
}
```

### **Etapa 2: Roteamento Inteligente de Mensagens**
```
[Producer Service] â†’ [Topic Router] â†’ [Kafka Topics]
```

**ğŸ› ï¸ Tecnologias:**
- **Spring Kafka**: Cliente Kafka para Java
- **Apache Kafka**: Plataforma de streaming distribuÃ­da
- **Custom Routing Logic**: Algoritmo de roteamento baseado em regras

**ğŸ“ Processo:**
1. **AnÃ¡lise do tipo de log** (level, service, categoria)
2. **AplicaÃ§Ã£o de regras de roteamento:**
   - `ERROR/FATAL` â†’ `error-logs` topic
   - `AUDIT` â†’ `audit-logs` topic  
   - `FINANCIAL` â†’ `financial-logs` topic
   - `INFO/DEBUG/WARN` â†’ `application-logs` topic

**ğŸ¯ ConfiguraÃ§Ã£o de Topics:**
```yaml
Topics:
  application-logs: { partitions: 3, retention: 7d, compression: snappy }
  error-logs: { partitions: 3, retention: 30d, compression: lz4 }
  audit-logs: { partitions: 2, retention: 90d, compression: gzip }
  financial-logs: { partitions: 4, retention: 365d, compression: lz4 }
```

### **Etapa 3: PersistÃªncia no Apache Kafka**
```
[Kafka Producer] â†’ [Partition Assignment] â†’ [Kafka Cluster] â†’ [Replication]
```

**ğŸ› ï¸ Tecnologias:**
- **Apache Kafka 2.8+**: Cluster de brokers
- **Apache Zookeeper**: CoordenaÃ§Ã£o de cluster (em transiÃ§Ã£o para KRaft)
- **Kubernetes StatefulSets**: OrquestraÃ§Ã£o de containers persistentes
- **Persistent Volumes**: Armazenamento durÃ¡vel

**ğŸ“ Processo:**
1. **Producer envia mensagem** com chave de particionamento
2. **Kafka determina partiÃ§Ã£o** (hash da chave ou round-robin)
3. **ReplicaÃ§Ã£o entre brokers** (replication-factor configurÃ¡vel)
4. **Acknowledgment para Producer** (acks=all para durabilidade)
5. **PersistÃªncia em disco** com compactaÃ§Ã£o configurada

**âš™ï¸ ConfiguraÃ§Ã£o de Cluster:**
```yaml
Kafka Cluster:
  Brokers: 3 replicas
  Partitions: 3-4 per topic
  Replication Factor: 2-3
  Min In-Sync Replicas: 2
  Retention: Variable by topic type
```

### **Etapa 4: Consumo e Processamento**
```
[Kafka Consumer] â†’ [Message Processing] â†’ [Business Logic] â†’ [Output Processing]
```

**ğŸ› ï¸ Tecnologias:**
- **Spring Kafka Consumer**: Cliente consumer reativo
- **Spring Boot Actuator**: Monitoramento e health checks
- **Micrometer**: MÃ©tricas e observabilidade
- **Circuit Breaker Pattern**: ResiliÃªncia contra falhas

**ğŸ“ Processo:**
1. **Consumer Group subscription** nos topics relevantes
2. **Polling de mensagens** (batch processing otimizado)
3. **DeserializaÃ§Ã£o JSON** para objetos Java
4. **Processamento de negÃ³cio:**
   - **Error Logs**: Alertas, notificaÃ§Ãµes, dashboards
   - **Audit Logs**: Compliance, relatÃ³rios de seguranÃ§a
   - **Financial Logs**: ReconciliaÃ§Ã£o, anÃ¡lise de fraude
   - **Application Logs**: Debugging, performance analysis

### **Etapa 5: Processamento EspecÃ­fico por Tipo**

#### **ğŸš¨ Error Logs Processing**
```
[Error Consumer] â†’ [Alert Engine] â†’ [Notification Service] â†’ [Dashboard Update]
```
- **AnÃ¡lise de padrÃµes** de erro
- **CorrelaÃ§Ã£o de eventos** relacionados
- **GeraÃ§Ã£o de alertas** automÃ¡ticos
- **AtualizaÃ§Ã£o de dashboards** em tempo real

#### **ğŸ” Audit Logs Processing** 
```
[Audit Consumer] â†’ [Compliance Engine] â†’ [Security Analysis] â†’ [Report Generation]
```
- **ValidaÃ§Ã£o de compliance** (GDPR, SOX, PCI-DSS)
- **AnÃ¡lise de seguranÃ§a** comportamental
- **GeraÃ§Ã£o de relatÃ³rios** regulatÃ³rios
- **Armazenamento de longo prazo**

#### **ğŸ’° Financial Logs Processing**
```
[Financial Consumer] â†’ [Fraud Detection] â†’ [Reconciliation] â†’ [Reporting]
```
- **DetecÃ§Ã£o de fraudes** em tempo real
- **ReconciliaÃ§Ã£o automÃ¡tica** de transaÃ§Ãµes
- **AnÃ¡lise de padrÃµes** financeiros
- **RelatÃ³rios regulatÃ³rios**

### **Etapa 6: Armazenamento e Arquivamento**
```
[Processed Data] â†’ [Database] â†’ [Data Lake] â†’ [Long-term Archive]
```

**ğŸ› ï¸ Tecnologias:**
- **PostgreSQL**: Dados estruturados e consultas complexas
- **Elasticsearch**: Busca full-text e anÃ¡lise de logs
- **Apache Hadoop/S3**: Data lake para big data
- **Apache Parquet**: Formato columnar para analytics

**ğŸ“ Processo:**
1. **Armazenamento imediato** em banco relacional
2. **IndexaÃ§Ã£o em Elasticsearch** para busca
3. **ETL para Data Lake** (processamento batch)
4. **Arquivamento** de dados antigos (cold storage)

## ğŸ”§ Tecnologias por Camada

### **ğŸ¯ Camada de AplicaÃ§Ã£o**
```yaml
Microservices:
  - Log Producer Service: Spring Boot 3.2, Java 17
  - Log Consumer Service: Spring Boot 3.2, Java 17
  - API Gateway: Spring Cloud Gateway
  - Configuration Service: Spring Cloud Config
```

### **âš¡ Camada de Messaging**
```yaml
Event Streaming:
  - Apache Kafka: Streaming platform
  - Zookeeper: Cluster coordination
  - Kafka Connect: Data integration
  - Schema Registry: Schema evolution
```

### **ğŸ—ï¸ Camada de Infraestrutura**
```yaml
Container Orchestration:
  - Kubernetes: Container orchestration
  - Docker: Containerization
  - Helm Charts: Package management
  - Istio: Service mesh (opcional)

Storage:
  - Persistent Volumes: Kafka data persistence
  - Network File System: Shared storage
  - Backup Solutions: Velero, Restic
```

### **ğŸ“Š Camada de Observabilidade**
```yaml
Monitoring Stack:
  - Prometheus: Metrics collection
  - Grafana: Visualization dashboards
  - Jaeger: Distributed tracing
  - ELK Stack: Log aggregation and analysis

Health Checks:
  - Spring Actuator: Application health
  - Kubernetes Probes: Container health
  - Custom Health Indicators: Business logic health
```

## ğŸ”„ PadrÃµes de ResiliÃªncia Implementados

### **ğŸ›¡ï¸ Producer Resilience**
- **Retries**: ConfiguraÃ§Ã£o de tentativas automÃ¡ticas
- **Circuit Breaker**: ProteÃ§Ã£o contra cascata de falhas
- **Bulkhead**: Isolamento de recursos crÃ­ticos
- **Timeout**: Timeouts configurÃ¡veis para operaÃ§Ãµes

### **ğŸ”„ Consumer Resilience**
- **Dead Letter Queue**: Mensagens com falha de processamento
- **Retry Policy**: PolÃ­tica de reprocessamento
- **Offset Management**: Controle manual de offsets
- **Graceful Shutdown**: FinalizaÃ§Ã£o segura de processamento

### **ğŸ“ˆ Scalability Patterns**
- **Auto-scaling**: Baseado em lag de consumer
- **Partition Strategy**: Balanceamento de carga
- **Consumer Groups**: ParalelizaÃ§Ã£o de processamento
- **Load Balancing**: DistribuiÃ§Ã£o inteligente de carga

## ğŸ“Š MÃ©tricas e Monitoramento

### **ğŸ¯ MÃ©tricas Coletadas**
```yaml
Producer Metrics:
  - Messages produced per second
  - Produce latency (p95, p99)
  - Error rate by topic
  - Batch size efficiency

Consumer Metrics:
  - Consumer lag by partition
  - Processing latency
  - Commit frequency
  - Rebalance frequency

Infrastructure Metrics:
  - Kafka broker CPU/Memory
  - Disk I/O utilization
  - Network throughput
  - JVM garbage collection
```

### **ğŸš¨ Alerting Rules**
- **High Consumer Lag**: > 10.000 mensagens
- **Producer Error Rate**: > 1% em 5 minutos
- **Broker Down**: Qualquer broker indisponÃ­vel
- **Disk Usage**: > 85% de utilizaÃ§Ã£o

## ğŸ¯ BenefÃ­cios da Arquitetura

### **âš¡ Performance**
- **Throughput**: 10.000+ mensagens/segundo
- **Latency**: < 100ms end-to-end (p95)
- **Scalability**: Auto-scaling baseado em demanda

### **ğŸ›¡ï¸ Confiabilidade**
- **Durabilidade**: ReplicaÃ§Ã£o multi-broker
- **Availability**: 99.9% uptime target
- **Disaster Recovery**: Backup e restore automÃ¡tico

### **ğŸ”§ Operabilidade**
- **Zero-downtime**: Deployment sem interrupÃ§Ã£o
- **Auto-healing**: RecuperaÃ§Ã£o automÃ¡tica de falhas
- **Monitoring**: Observabilidade completa do pipeline

Este workflow representa um sistema robusto e escalÃ¡vel para processamento de logs em tempo real, com foco em confiabilidade, performance e observabilidade. ğŸš€
