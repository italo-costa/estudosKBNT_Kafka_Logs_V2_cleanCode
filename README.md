# Sistema de Gerenciamento Virtual de Estoque

[![Architecture](https://img.shields.io/badge/Architecture-Hexagonal-blue)](docs/HEXAGONAL_ARCHITECTURE.md)
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-2.7+-green)](https://spring.io/projects/spring-boot)
[![Kafka](https://img.shields.io/badge/Kafka-Red%20Hat%20AMQ%20Streams-red)](https://www.redhat.com/en/technologies/cloud-computing/openshift/cloud-services/amq)
[![PostgreSQL](https://img.shields.io/badge/Databa        subgraph "ğŸ”Œ Output Adapters"
            KAFKA_PUB[ğŸ”¥ KafkaPublisherAdapter<br/>**ğŸš€ OutputAdapter: EventPublishingAdapter**<br/>Event Publishing - Spring Kafka 3.0<br/>ğŸ¯ Responsibility: Message Broker Integration]
            JPA_REPO[ğŸ—„ï¸ JpaRepositoryAdapter<br/>**ğŸ’¾ OutputAdapter: PersistenceAdapter**<br/>Data Persistence - Spring Data JPA<br/>ğŸ¯ Responsibility: Database Operations]
            PROMETHEUS[ğŸ“Š PrometheusAdapter<br/>**ğŸ“ˆ OutputAdapter: MetricsAdapter**<br/>Metrics - Micrometer + Prometheus<br/>ğŸ¯ Responsibility: Observability Data Export]
        endstgreSQL-blue)](https://www.postgresql.org/)

Sistema distribuÃ­do de microserviÃ§os para gerenciamento de estoque virtual implementando arquitetura hexagonal e padrÃµes DDD (Domain-Driven Design) com comunicaÃ§Ã£o via Red Hat AMQ Streams (Kafka).

## ğŸ“‹ VisÃ£o Geral

O sistema Ã© composto por dois microserviÃ§os principais:

1. **Virtual Stock Service** (Microservice A): Gerenciamento de estoque virtual com arquitetura hexagonal
2. **ACL Virtual Stock Service** (Microservice B): Anti-Corruption Layer para integraÃ§Ã£o com sistemas externos

## ğŸ—ï¸ Arquitetura

```
Virtual Stock Service  â”€â”€â–º Red Hat AMQ Streams (Kafka) â”€â”€â–º ACL Virtual Stock Service â”€â”€â–º External Systems
  (Hexagonal Arch)                                            (Anti-Corruption Layer)
```

### PadrÃµes Implementados

- **Hexagonal Architecture (Ports & Adapters)**
- **Domain-Driven Design (DDD)**
- **Anti-Corruption Layer (ACL)**
- **Event-Driven Architecture**
- **CQRS (Command Query Responsibility Segregation)**

## ğŸš€ Tecnologias

### Core Technologies
- **Java 17+**
- **Spring Boot 2.7+**
- **Spring Kafka**
- **PostgreSQL**
- **Red Hat AMQ Streams (Apache Kafka)**

### Infrastructure
- **Docker & Docker Compose**
- **Strimzi Operator** (Kubernetes Kafka)
- **Elasticsearch** (Logging alternativo)
- **Kibana** (Dashboard e visualizaÃ§Ã£o)

### Monitoring & Logging
- **SLF4J + Logback**
- **MDC (Mapped Diagnostic Context)**
- **Enhanced Structured Logging**
- **Performance Metrics**

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ microservices/
â”‚   â”œâ”€â”€ virtual-stock-service/           # Microservice A - Hexagonal Architecture
â”‚   â”‚   â””â”€â”€ src/main/java/com/kbnt/virtualstock/
â”‚   â”‚       â”œâ”€â”€ domain/                  # Domain Layer
â”‚   â”‚       â”‚   â”œâ”€â”€ model/              # Entities, Value Objects, Events
â”‚   â”‚       â”‚   â””â”€â”€ port/               # Input/Output Ports
â”‚   â”‚       â”œâ”€â”€ application/            # Application Layer
â”‚   â”‚       â”‚   â””â”€â”€ service/            # Use Cases Implementation
â”‚   â”‚       â””â”€â”€ infrastructure/         # Infrastructure Layer
â”‚   â”‚           â””â”€â”€ adapter/            # Input/Output Adapters
â”‚   â”‚
â”‚   â””â”€â”€ kbnt-stock-consumer-service/    # Microservice B - ACL
â”‚       â””â”€â”€ src/main/java/com/estudoskbnt/consumer/
â”‚           â”œâ”€â”€ service/                # Consumer Services
â”‚           â”œâ”€â”€ entity/                 # JPA Entities
â”‚           â”œâ”€â”€ repository/             # Data Repositories
â”‚           â””â”€â”€ config/                 # Configuration
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ kafka/                          # Kafka/Strimzi configurations
â”‚   â”œâ”€â”€ elasticsearch/                  # ELK Stack configurations
â”‚   â””â”€â”€ docker/                         # Docker configurations
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start-complete-environment.ps1  # Environment startup
â”‚   â”œâ”€â”€ traffic-test/                   # Load testing scripts
â”‚   â””â”€â”€ logging-demo/                   # Logging demonstrations
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ HEXAGONAL_ARCHITECTURE.md      # Architecture documentation
    â”œâ”€â”€ API_DOCUMENTATION.md           # API specifications
    â””â”€â”€ DEPLOYMENT_GUIDE.md            # Deployment instructions
```

## ğŸ”§ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos

- Java 17+
- Docker & Docker Compose
- Maven 3.8+
- PowerShell (Windows) ou Bash (Linux/Mac)

### ExecuÃ§Ã£o RÃ¡pida

1. **Clone o repositÃ³rio**:
   ```bash
   git clone <repository-url>
   cd estudosKBNT_Kafka_Logs
   ```

2. **Inicie o ambiente completo**:
   ```powershell
   # Windows PowerShell
   .\scripts\start-complete-environment.ps1
   
   # Linux/Mac
   ./scripts/start-complete-environment.sh
   ```

3. **Aguarde a inicializaÃ§Ã£o**:
   - Virtual Stock Service: `http://localhost:8080`
   - ACL Virtual Stock Service: `http://localhost:8081`
   - Kafka UI: `http://localhost:8082`
   - Elasticsearch: `http://localhost:9200`
   - Kibana: `http://localhost:5601`

### ExecuÃ§Ã£o Individual

#### Virtual Stock Service (Microservice A)

```bash
cd microservices/virtual-stock-service
mvn spring-boot:run
```

#### ACL Virtual Stock Service (Microservice B)

```bash
cd microservices/kbnt-stock-consumer-service
mvn spring-boot:run
```

## ğŸ“– APIs

### Virtual Stock Service APIs

#### Criar Estoque
```http
POST /api/v1/virtual-stock/stocks
Content-Type: application/json

{
  "productId": "PROD-001",
  "symbol": "AAPL",
  "productName": "Apple Stock",
  "initialQuantity": 100,
  "unitPrice": 150.00,
  "createdBy": "system"
}
```

#### Atualizar Quantidade
```http
PUT /api/v1/virtual-stock/stocks/{stockId}/quantity
Content-Type: application/json

{
  "newQuantity": 150,
  "updatedBy": "user123",
  "reason": "Stock replenishment"
}
```

#### Reservar Estoque
```http
POST /api/v1/virtual-stock/stocks/{stockId}/reserve
Content-Type: application/json

{
  "quantityToReserve": 10,
  "reservedBy": "order-service",
  "reason": "Order #12345"
}
```

#### Consultar Estoque
```http
GET /api/v1/virtual-stock/stocks/{stockId}
GET /api/v1/virtual-stock/stocks
```

## ï¿½ Logging Estruturado

O sistema implementa logging estruturado com identificaÃ§Ã£o de componentes:

### Formato de Log

```
2025-08-30 15:30:45.123 [main] INFO [VIRTUAL-STOCK] [RestController] [msg-uuid] [virtual-stock-updates] com.kbnt.virtualstock.infrastructure.adapter.input.rest.VirtualStockController - Stock created successfully
```

### Componentes Identificados

- **VIRTUAL-STOCK**: Virtual Stock Service
- **ACL-VIRTUAL-STOCK**: ACL Virtual Stock Service  
- **RED-HAT-AMQ-STREAMS**: Kafka Operations
- **EXTERNAL-API**: External System Integrations
- **DATABASE-OPERATION**: Database Operations

### MDC Context

- `component`: Identificador do componente
- `owner`: Classe/serviÃ§o responsÃ¡vel
- `messageId`: ID de correlaÃ§Ã£o
- `topic`: TÃ³pico Kafka
- `operation`: Tipo de operaÃ§Ã£o
- `duration`: Tempo de execuÃ§Ã£o

## ğŸ§ª Testes

### Testes UnitÃ¡rios
```bash
mvn test
```

### Testes de IntegraÃ§Ã£o
```bash
mvn verify
```

### Testes de Carga
```powershell
# Teste com 50 mensagens
.\scripts\final-traffic-test.ps1 -TotalMessages 50

# Teste com dashboard
.\scripts\demo-traffic-test.ps1 -TotalMessages 30 -Verbose
```

## ğŸ“Š Monitoramento

### Dashboard de TrÃ¡fego

Execute o teste com dashboard interativo:
```powershell
.\scripts\final-traffic-test.ps1 -TotalMessages 30
```

O dashboard inclui:
- Status dos serviÃ§os
- MÃ©tricas de performance
- Taxa de sucesso/erro
- Logs de mensagens em tempo real
- GrÃ¡ficos de throughput

### MÃ©tricas DisponÃ­veis

- **Throughput**: Mensagens por segundo
- **LatÃªncia**: Tempo de processamento end-to-end
- **Taxa de Sucesso**: Percentual de mensagens processadas com sucesso
- **UtilizaÃ§Ã£o de Recursos**: CPU, MemÃ³ria, Disk I/O
- **SaÃºde dos TÃ³picos Kafka**: PartiÃ§Ãµes, Offsets, Lag

## ğŸƒâ€â™‚ï¸ Troubleshooting

### Problemas Comuns

1. **Kafka nÃ£o inicializa**:
   ```bash
   docker-compose -f infrastructure/kafka/docker-compose.yml down
   docker-compose -f infrastructure/kafka/docker-compose.yml up -d
   ```

2. **MicroserviÃ§os nÃ£o conectam ao Kafka**:
   - Verifique se o Kafka estÃ¡ rodando: `docker ps`
   - Verifique os logs: `docker-compose logs kafka`

3. **Logs nÃ£o aparecem**:
   - Verifique se o diretÃ³rio `logs/` existe
   - Verifique as permissÃµes de escrita

### Health Checks

```bash
# Virtual Stock Service
curl http://localhost:8080/actuator/health

# ACL Virtual Stock Service  
curl http://localhost:8081/actuator/health

# Kafka Cluster
curl http://localhost:8082/clusters
```

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Arquitetura Hexagonal](docs/HEXAGONAL_ARCHITECTURE.md)
- [Guia de Deploy](docs/DEPLOYMENT_GUIDE.md)
- [DocumentaÃ§Ã£o de APIs](docs/API_DOCUMENTATION.md)
- [Troubleshooting](docs/TROUBLESHOOTING.md)

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ License

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¥ Team

- **KBNT Development Team**
- VersÃ£o: 2.0.0
- Data: 2025-08-30

---

**â­ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!**
- **Fluxos sÃ­ncronos e assÃ­ncronos** de processamento
- **Arquitetura Hexagonal interna** dos microserviÃ§os
- **EstratÃ©gias de roteamento** de tÃ³picos Kafka
- **Monitoramento e observabilidade** completos

**ğŸ‘‰ [Visualizar Diagramas Completos](./docs/DIAGRAMAS_ARQUITETURA_COMPLETOS.md)**

### ğŸ—ï¸ **Diagrama Simplificado**

```mermaid
graph TB
    subgraph "External Systems"
        API[ğŸŒ External API]
        MON[ğŸ“Š Prometheus]
    end
    
    subgraph "Microservices Architecture"
        subgraph "Log Producer Service"
            REST[ğŸ“¡ REST Controller] --> PROD_APP[âš™ï¸ Production UseCase]
            PROD_APP --> VALID[âœ… Validation Service]
            PROD_APP --> ROUTE[ğŸ”„ Routing Service]
            VALID --> KAFKA_PUB[ğŸ“¤ Kafka Publisher]
            ROUTE --> KAFKA_PUB
            KAFKA_PUB --> METRICS_P[ï¿½ Metrics]
        end
        
        subgraph "Message Broker"
            KAFKA[ğŸ”¥ Apache Kafka<br/>AMQ Streams]
        end
        
        subgraph "Log Consumer Service"
            KAFKA_CONS[ğŸ“¥ Kafka Consumer] --> PROC_APP[âš™ï¸ Processing UseCase]
            PROC_APP --> EXT_API[ğŸŒ External API Client]
            PROC_APP --> PERSIST[ğŸ’¾ Log Persistence]
            EXT_API --> METRICS_C[ğŸ“ˆ Metrics]
        end
    end
    
    REST -.->|HTTP Logs| KAFKA_PUB
    KAFKA_PUB -->|Publish| KAFKA
    KAFKA -->|Consume| KAFKA_CONS
    EXT_API -->|REST Calls| API
    METRICS_P -->|Metrics| MON
    METRICS_C -->|Metrics| MON
    
    style KAFKA fill:#ff6b6b
    style REST fill:#4ecdc4
    style EXT_API fill:#45b7d1
    style MON fill:#96ceb4
```

### ğŸ” **Detailed Architecture Documentation**

For comprehensive architectural views, see our detailed diagrams:

- ğŸ—ï¸ [**Diagramas de Arquitetura Atualizados - Virtual Stock System**](docs/DIAGRAMAS_ARQUITETURA_COMPLETOS.md)
  - Arquitetura hexagonal completa com Domain-Driven Design
  - Deployment Kubernetes enterprise-ready com especificaÃ§Ãµes de recursos
  - Fluxo de mensagens Kafka com tÃ³picos de prioridade e estratÃ©gias de retry
  - Diagramas de sequÃªncia mostrando fluxos sÃ­ncronos e assÃ­ncronos
  - Monitoramento e observabilidade completos (Prometheus + Grafana + ELK)
  - CenÃ¡rios de teste de carga e simulaÃ§Ã£o de performance

### ğŸ“‹ **Architecture Highlights**

| Component | Technology | Sync/Async | Purpose |
|-----------|------------|------------|---------|
| **HTTP API** | Spring Boot REST | âš¡ SYNC | Log ingestion endpoint |
| **Message Publishing** | Kafka Producer | ğŸ”„ ASYNC | Reliable message delivery |
| **Message Consumption** | Kafka Consumer | ğŸ”„ ASYNC | Background processing |
| **External Integration** | REST Client | âš¡ SYNC | Third-party API calls |
| **Metrics Collection** | Micrometer/Prometheus | ğŸ”„ ASYNC | Observability |

---

- [ğŸ¯ Project Overview](#-project-overview)
- [ğŸ›ï¸ Architecture Diagram](#ï¸-architecture-diagram)
- [âš¡ Quick Start](#-quick-start)
- [ğŸ—ï¸ Hexagonal Architecture](#ï¸-hexagonal-architecture)
- [ğŸ”„ Workflow Documentation](#-workflow-documentation)
- [ğŸš€ Deployment Options](#-deployment-options)
- [ğŸ“Š Monitoring & Metrics](#-monitoring--metrics)
- [ğŸ§ª Testing](#-testing)
- [ğŸ“š Documentation](#-documentation)

---

## âš¡ **Quick Start**

### ğŸ³ **Option 1: Docker Compose (Recommended for Development)**

```bash
# Clone the repository
git clone https://github.com/yourusername/estudosKBNT_Kafka_Logs.git
cd estudosKBNT_Kafka_Logs

# Start entire infrastructure
docker-compose up -d

# Check services status
docker-compose ps

# View logs
docker-compose logs -f log-producer-service
```

### â˜¸ï¸ **Option 2: Kubernetes (Production-Ready)**

```bash
# Deploy infrastructure (Kafka, Zookeeper, Monitoring)
kubectl apply -f kubernetes/

# Deploy microservices
kubectl apply -f hybrid-deployment/

# Check deployment status
kubectl get pods -n kafka
kubectl get services -n kafka
```

### ğŸ’» **Option 3: Local Development**

```bash
# Start Kafka locally
./scripts/start-kafka.sh

# Run Producer Service
cd microservices/log-producer-service
./mvnw spring-boot:run

# Run Consumer Service
cd ../log-consumer-service  
./mvnw spring-boot:run
```

---

## ï¿½ï¸ Arquitetura Hexagonal

### ğŸ¯ Sistema de Gerenciamento Virtual de Estoque

```mermaid
graph TB
    subgraph "ğŸŒ External Clients"
        TRADER[ğŸ‘¤ Stock Trader]
        MOBILE[ğŸ“± Mobile App]
        WEB[ğŸŒ Web Portal]
    end
    
    subgraph "ğŸ›ï¸ Virtual Stock Service (Hexagonal Architecture)"
        subgraph "ğŸ”Œ Input Adapters"
            REST_CTRL[ğŸŒ VirtualStockController<br/>**ğŸ“‹ InputPort: StockManagementInputPort**<br/>@RestController - Spring Boot 3.2<br/>ğŸ¯ Responsibility: HTTP Request Handling]
            HEALTH_CTRL[ğŸ’š HealthController<br/>**ğŸ“‹ InputPort: HealthCheckInputPort**<br/>@RestController - Spring Actuator<br/>ğŸ¯ Responsibility: Health Monitoring]
        end
        
        subgraph "ğŸ¯ Domain Core"
            STOCK_AGG[ğŸ“¦ Stock Aggregate<br/>**ğŸ›ï¸ AggregateRoot: StockAggregate**<br/>Business Logic - Pure Java 17<br/>ğŸ¯ Responsibility: Business Rules Enforcement]
            STOCK_EVENT[ğŸ“¢ StockUpdatedEvent<br/>**ğŸ“¤ DomainEvent: StockDomainEvent**<br/>Domain Events - Event Sourcing<br/>ğŸ¯ Responsibility: Domain State Changes]
            BIZ_RULES[ğŸ“‹ Business Rules<br/>**âš–ï¸ DomainService: StockBusinessRules**<br/>canReserve, isLowStock - Pure Logic<br/>ğŸ¯ Responsibility: Business Validation]
        end
        
        subgraph "âš™ï¸ Application Layer"
            STOCK_UC[ğŸ¯ StockManagementUseCase<br/>**ğŸ”„ ApplicationService: StockApplicationService**<br/>Use Cases - Spring @Service<br/>ğŸ¯ Responsibility: Business Workflow Orchestration]
            EVENT_PUB[ğŸ“¤ StockEventPublisher<br/>**ğŸ“¡ OutputPort: EventPublisherOutputPort**<br/>Event Orchestration - Async Publishing<br/>ğŸ¯ Responsibility: Domain Event Distribution]
        end
        
        subgraph "ï¿½ Output Adapters"
            KAFKA_PUB[ğŸ”¥ KafkaPublisherAdapter<br/>Event Publishing]
            JPA_REPO[ï¿½ï¸ JpaRepositoryAdapter<br/>Data Persistence]
            PROMETHEUS[ğŸ“Š PrometheusAdapter<br/>Metrics]
        end
    end
    
    subgraph "ğŸ”¥ Red Hat AMQ Streams - Event Backbone"
        TOPIC_STOCK[ğŸ“¢ **TopicManager: StockEventsManager**<br/>virtual-stock-events Topic - Apache Kafka 3.5.0<br/>ğŸ”„ Partitions: 6, Replication: 3<br/>ğŸ¯ **Responsibility: Main Business Events Distribution**]
        TOPIC_HIGH[âš¡ **TopicManager: HighPriorityEventsManager**<br/>high-priority-events Topic - Apache Kafka 3.5.0<br/>ğŸ”„ Partitions: 3, Replication: 3<br/>ğŸ¯ **Responsibility: Critical Trading Events**]
    end
    
    subgraph "ğŸ›¡ï¸ ACL Virtual Stock Service - Anti-Corruption Layer"
        KAFKA_CONS[ğŸ”¥ KafkaConsumerAdapter<br/>**ğŸ“¥ InputAdapter: EventConsumerAdapter**<br/>Event Processing - Spring @KafkaListener<br/>ğŸ¯ **Responsibility: External Event Consumption**]
        MSG_PROC[âš™ï¸ MessageProcessingService<br/>**ğŸ›¡ï¸ ApplicationService: AntiCorruptionService**<br/>Business Logic - Data Translation<br/>ğŸ¯ **Responsibility: Format Translation and Validation**]
        EXT_CLIENT[ğŸŒ ExternalApiClient<br/>**ğŸ”— OutputAdapter: IntegrationAdapter**<br/>Third-party Integration - Spring WebClient<br/>ğŸ¯ **Responsibility: External System Communication**]
    end
    
    subgraph "ğŸ’¾ Data Layer"
        POSTGRES_DB[(ğŸ˜ PostgreSQL<br/>ACID Transactions)]
        EXT_API[ğŸŒ External Trading API<br/>Stock Price Feeds]
    end

    %% Flow connections
    TRADER --> REST_CTRL
    MOBILE --> REST_CTRL
    WEB --> REST_CTRL
    
    REST_CTRL --> STOCK_UC
    STOCK_UC --> STOCK_AGG
    STOCK_AGG --> STOCK_EVENT
    STOCK_UC --> EVENT_PUB
    
    EVENT_PUB --> KAFKA_PUB
    STOCK_UC --> JPA_REPO
    
    KAFKA_PUB --> TOPIC_STOCK
    KAFKA_PUB --> TOPIC_HIGH
    
    TOPIC_STOCK --> KAFKA_CONS
    TOPIC_HIGH --> KAFKA_CONS
    
    KAFKA_CONS --> MSG_PROC
    MSG_PROC --> EXT_CLIENT
    
    JPA_REPO --> POSTGRES_DB
    EXT_CLIENT --> EXT_API
    
    style STOCK_AGG fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px
    style STOCK_EVENT fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    style KAFKA_PUB fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    style KAFKA_CONS fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
```

### ğŸ”„ Fluxo de NegÃ³cio: Gerenciamento de Estoque

```mermaid
sequenceDiagram
    participant Trader as Professional_Stock_Trader
    participant VS as Virtual_Stock_Service_Hexagonal
    participant Kafka as Red_Hat_AMQ_Streams_Platform
    participant ACL as ACL_Anti_Corruption_Layer
    participant ExtAPI as External_Trading_API_Gateway

    Note over Trader,ExtAPI: ğŸ¯ Enhanced Stock Creation and Management Workflow

    rect rgb(240, 248, 255)
        Note over Trader,VS: PHASE 1: High-Performance Stock Creation
        Trader->>Plus_VS: [1] ğŸ“ˆ POST /api/v1/virtual-stock/stocks<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ·ï¸ Symbol: AAPL | Quantity: 150 units<br/>ğŸ’° Unit Price: $150.00 | Created By: trader-007<br/>ğŸ” JWT Token: Bearer eyJ0eXAi...<br/>âš¡ Response Time Target: less than 1ms<br/>ğŸ“Š Request ID: req-12345-abcd
        
        VS->>VS: [2] ğŸ” Domain Validation Layer<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>âœ… Symbol format validation (^[A-Z]{1,5}$)<br/>ğŸ’µ Price range check ($0.01 - $10,000)<br/>ğŸ“Š Quantity bounds (1 - 1,000,000)<br/>ğŸ”’ User authorization verification<br/>â±ï¸ Validation Time: <0.5ms
        
        VS->>VS: [3] ğŸ—ï¸ Create Stock Aggregate Root<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ Aggregate: VirtualStock Entity<br/>ğŸ†” Generated StockId: STK-AAPL-001<br/>ğŸ¯ Domain Event: StockCreatedEvent<br/>ğŸ’¾ In-Memory Repository Storage<br/>âš¡ Processing Time: <0.2ms
        
        VS->>Plus_Kafka: [4] ğŸš€ Publish StockCreatedEvent<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¢ Topic: virtual-stock-events<br/>ğŸ”‘ Partition Key: AAPL<br/>ğŸ“‹ Event Schema: Avro v2.1<br/>ğŸ’¾ Message Size: 1.2KB<br/>ğŸ”„ Acknowledgment: all replicas<br/>âš¡ Publish Latency: 2.3ms average
        Kafka-->>-VS: [5] ğŸ“¨ Event Successfully Published<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>âœ… Partition: 0 | Offset: 12847<br/>ğŸ•’ Timestamp: 2024-12-30T15:30:45.123Z<br/>ğŸ”„ Replication Status: 3/3 confirmed
        
        VS-->>-Trader: [6] ğŸ‰ 201 CREATED - Stock Successfully Created<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“Š Stock ID: STK-AAPL-001<br/>ğŸ’° Total Portfolio Value: $22,500.00<br/>ğŸ“ˆ Available Quantity: 150 units<br/>ğŸ•’ Created At: 2024-12-30T15:30:45.125Z<br/>âš¡ Total Response Time: 3.1ms<br/>ğŸ¯ Transaction ID: txn-abc-123
    end

    Note over Kafka,ExtAPI: ğŸ”„ Asynchronous Integration Processing Pipeline

    rect rgb(255, 248, 240)
        Note over Kafka,ACL: PHASE 2: Event-Driven Integration Processing
        Kafka->>Plus_ACL: [7] ğŸ“¥ Consume StockCreatedEvent<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ‘¥ Consumer Group: stock-acl-consumers<br/>ğŸ“¨ Message Processing Rate: 107.73 msg/s<br/>ğŸ”„ Offset Management: Automatic commit<br/>âš¡ Processing Latency: 8ms average<br/>ğŸ“Š Consumer Lag: 0 messages
        
        ACL->>ACL: [8] ğŸ”„ Anti-Corruption Translation Layer<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ”€ Internal Domain to External API Format<br/>ğŸ“‹ Schema Mapping: Internal â†’ External DTOs<br/>ğŸ”’ Security Token Exchange<br/>ğŸ’± Currency Conversion (if required)<br/>ğŸ“Š Data Enrichment and Validation<br/>âš¡ Translation Time: 15ms average
        
        ACL->>Plus_ExtAPI: [9] ğŸŒ POST /api/trading/stock-created<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“ˆ External System Notification<br/>ğŸ” API Key Authentication<br/>ğŸ’¼ Trading Platform Integration<br/>ğŸ“Š Risk Management System Update<br/>ğŸ’° Portfolio Valuation Sync<br/>âš¡ External API Call: 45ms average
        ExtAPI-->>-ACL: [10] âœ… 200 OK - External System Updated<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“Š External Reference: EXT-AAPL-789<br/>ğŸ•’ Processing Completed: 15:30:45.189Z<br/>âœ… Downstream Systems Synchronized
        
        ACL-->>-Kafka: [11] ğŸ“ Processing Complete Acknowledgment<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>âœ… Message Successfully Processed<br/>ğŸ“Š Total Processing Time: 68ms<br/>ğŸ”„ Offset Committed: 12847<br/>ğŸ¯ End-to-end Traceability: Maintained
    end

    Note over Trader,ExtAPI: ğŸ“Š High-Volume Stock Update Operations

    rect rgb(248, 255, 248)
        Note over Trader,VS: PHASE 3: Real-time Stock Updates
        Trader->>Plus_VS: [12] ğŸ“ˆ PUT /api/v1/virtual-stock/stocks/STK-AAPL-001/quantity<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ”„ Quantity Update: 150 â†’ 200 units<br/>ğŸ‘¤ Updated By: trader-007<br/>ğŸ“ Reason: "Market volatility adjustment"<br/>ğŸ•’ Update Timestamp: 15:31:15.456Z<br/>âš¡ High-frequency Trading Context<br/>ğŸ¯ Target Response Time: less than 0.5ms
        
        VS->>VS: [13] ğŸ”§ Update Stock Aggregate Business Logic<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“Š Previous State: qty=150, value=$22,500<br/>ğŸ”„ New State: qty=200, value=$30,000<br/>ğŸ“¢ Domain Event: StockQuantityUpdatedEvent<br/>ğŸ’¾ Aggregate Version Increment: v2<br/>âš¡ Business Logic Processing: <0.3ms
        
        VS->>Plus_Kafka: [14] ğŸš€ Publish StockQuantityUpdatedEvent<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¢ Topic: virtual-stock-events<br/>ğŸ”‘ Partition Key: AAPL<br/>ğŸ“Š Delta: 50 more units | 7500 more value<br/>ğŸ’¾ Event Payload: 1.8KB<br/>ğŸ”„ Producer Acknowledgment: Required<br/>âš¡ Message Publish Time: 1.9ms
        Kafka-->>-VS: [15] âœ… Update Event Successfully Published<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“Š Partition: 0 | Offset: 12848<br/>ğŸ•’ Event Timestamp: 15:31:15.458Z<br/>ğŸ”„ High-throughput Processing Confirmed
        
        VS-->>-Trader: [16] ğŸ¯ 200 OK - Stock Updated Successfully<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“Š Updated Quantity: 200 units<br/>ğŸ’° New Total Value: $30,000.00<br/>ğŸ“ˆ Portfolio Growth: 7500 more (33.3% increase)<br/>ğŸ•’ Last Modified: 15:31:15.458Z<br/>âš¡ Total Update Time: 2.4ms<br/>âœ… High-performance Update Confirmed
    end

    rect rgb(255, 248, 255)
        Note over Kafka,ExtAPI: PHASE 4: Downstream System Synchronization
        Kafka->>Plus_ACL: [17] ğŸ“¥ Consume StockQuantityUpdatedEvent<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>âš¡ High-frequency Event Processing<br/>ğŸ“Š Consumer Performance: 107 msg/s and more<br/>ğŸ”„ Real-time Delta Processing<br/>ğŸ“ˆ Event Ordering Maintained<br/>â±ï¸ Processing Initiated: 15:31:15.466Z
        
        ACL->>Plus_ExtAPI: [18] ğŸŒ PUT /api/trading/stock-updated<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“Š Stock Update Notification<br/>ğŸ”„ Quantity Delta: 50 more units<br/>ğŸ’° Value Delta: 7500 more<br/>ğŸ¯ Real-time Portfolio Sync<br/>ğŸ“ˆ Risk Management Update<br/>âš¡ External API Processing: 42ms
        ExtAPI-->>-ACL: [19] âœ… 200 OK - External Systems Updated<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“Š Downstream Sync Complete<br/>ğŸ’¼ Trading Platform Updated<br/>ğŸ“ˆ Portfolio Rebalanced<br/>ğŸ•’ Sync Completed: 15:31:15.508Z
        
        ACL-->>-Kafka: [20] ğŸ“ Update Processing Complete<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>âœ… End-to-end Update Successful<br/>ğŸ“Š Total Processing Time: 42ms<br/>ğŸ”„ Message Offset: 12848 committed<br/>ğŸ¯ System Consistency Maintained
    end

    Note over Trader,ExtAPI: ğŸ¯ System Performance Summary - 20 Steps Total
    Note over Trader,ExtAPI: âš¡ 580+ requests/second sustained<br/>ğŸ“Š 107.73 messages/second throughput<br/>ğŸ¯ Sub-millisecond response times<br/>âœ… Zero message loss achieved<br/>ğŸ”„ 18,600+ operations processed<br/>ğŸ“ˆ 3,449 events published successfully
```

### ï¿½ **Business Domain: Virtual Stock Management**

O sistema implementa um **domÃ­nio de negÃ³cio completo** para gerenciamento de estoque virtual:

#### **ğŸ¯ Casos de Uso Implementados:**
- **ï¿½ CriaÃ§Ã£o de Estoque**: Registrar novos produtos/ativos (AAPL, MSFT)
- **ï¿½ AtualizaÃ§Ã£o de Quantidade**: Modificar estoque disponÃ­vel  
- **ï¿½ Reserva de Estoque**: Reservar unidades para trading
- **ğŸ’° AtualizaÃ§Ã£o de PreÃ§o**: Modificar preÃ§o unitÃ¡rio
- **ï¿½ Consultas**: Buscar por ID, produto ou sÃ­mbolo

#### **ğŸ“ˆ Estados de NegÃ³cio:**
```java
public enum StockStatus {
    AVAILABLE,      // DisponÃ­vel para trading
    RESERVED,       // Reservado para operaÃ§Ãµes
    OUT_OF_STOCK,   // Sem estoque
    DISCONTINUED,   // Produto descontinuado  
    PENDING_RESTOCK // Aguardando reabastecimento
}
```

#### **ğŸ’¼ Exemplo Real Executado:**
```json
// CriaÃ§Ã£o: AAPL com 150 unidades a $150.00 = $22,500
// AtualizaÃ§Ã£o: 150 â†’ 200 unidades = $30,000
// Evento: StockUpdatedEvent propagado via Kafka
// ACL: Processa e integra com sistemas externos
```

---

## ğŸš€ **Deployment Options**

### ğŸ“‹ **Environment Matrix**

| Environment | Kafka | Database | Monitoring | External APIs |
|-------------|-------|----------|------------|---------------|
| **Development** | Docker | H2 | Console | Mock |
| **Testing** | Testcontainers | PostgreSQL | Prometheus | Stubbed |
| **Staging** | AMQ Streams | PostgreSQL | Full Stack | Real |
| **Production** | AMQ Streams | PostgreSQL + HA | Full Stack | Real |

### ğŸ”§ **Configuration Profiles**

```yaml
# application-local.yml
spring:
  kafka:
    bootstrap-servers: localhost:9092
  
# application-kubernetes.yml  
spring:
  kafka:
    bootstrap-servers: kafka-cluster-kafka-bootstrap.kafka.svc:9092
```

---

## ğŸ“Š **Monitoring & Metrics**

### ğŸ¯ **Key Performance Indicators**

#### Producer Metrics
- ğŸ“ˆ **Throughput**: Logs published per second
- â±ï¸ **Latency**: End-to-end processing time
- âŒ **Error Rate**: Validation and publishing failures
- ğŸ”„ **Topic Distribution**: Message distribution across topics

#### Consumer Metrics
- ğŸ“¥ **Consumption Rate**: Messages processed per second
- ğŸŒ **API Response Times**: External API call latency
- âœ… **Success Rate**: Processing success percentage
- ğŸ”„ **Retry Patterns**: Failed message retry statistics

### ğŸ“Š **Prometheus Metrics Examples**

```prometheus
# Total logs published
logs_published_total{service="log-producer"} 1547

# API response time histogram
api_response_time_seconds{endpoint="/external-api"} 0.245

# Error rate by log level
logs_level_error_total{level="ERROR"} 23
```

---

## ğŸ§ª **Testing**

### ğŸ¯ **Testing Strategy**

| Test Type | Coverage | Tools | Purpose |
|-----------|----------|-------|---------|
| **Unit** | Domain Layer | JUnit 5 | Business Logic |
| **Integration** | Use Cases | Spring Boot Test | Component Interaction |
| **Contract** | APIs | Spring Cloud Contract | API Contracts |
| **E2E** | Full Flow | Testcontainers | End-to-End Scenarios |

### ğŸ”§ **Running Tests**

```bash
# Unit tests (fast)
./mvnw test

# Integration tests
./mvnw verify -P integration-tests

# E2E tests with Testcontainers
./mvnw verify -P e2e-tests

# All tests with coverage
./mvnw clean verify jacoco:report
```

---

## ğŸ“š **Documentation**

### ğŸ“– **Available Documentation**

- ğŸ—ï¸ [**Hexagonal Architecture Guide**](docs/ARQUITETURA_HEXAGONAL.md)
- ğŸ”„ [**Integration Workflow**](docs/WORKFLOW_INTEGRACAO.md)
- ğŸ“Š [**Implementation Status**](docs/HEXAGONAL_IMPLEMENTATION_STATUS.md)
- ğŸ¨ [**Complete Architecture Diagrams**](docs/DIAGRAMAS_ARQUITETURA_COMPLETOS.md)
- ğŸš€ [**Deployment Guide**](hybrid-deployment/README.md)
- âš™ï¸ [**VS Code Setup**](.vscode/README.md)
- ğŸ§ª [**Testing Guide**](docs/TESTING.md)

### ğŸ”— **External Resources**

- [Hexagonal Architecture](https://alistair.cockburn.us/hexagonal-architecture/)
- [Spring Boot Documentation](https://spring.io/projects/spring-boot)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Red Hat AMQ Streams](https://access.redhat.com/products/red-hat-amq/)

---

## ğŸ‰ **Getting Started**

1. **ğŸ“‚ Clone the repository**
   ```bash
   git clone https://github.com/yourusername/estudosKBNT_Kafka_Logs.git
   ```

2. **ğŸ“š Read the documentation**
   - Start with [Architecture Guide](docs/ARQUITETURA_HEXAGONAL.md)
   - Review [Implementation Status](docs/HEXAGONAL_IMPLEMENTATION_STATUS.md)

3. **ğŸš€ Choose your deployment**
   - **Development**: Use Docker Compose
   - **Production**: Deploy to Kubernetes

4. **ğŸ§ª Run tests**
   ```bash
   ./mvnw clean verify
   ```

5. **ğŸ“Š Monitor metrics**
   - Access Prometheus: `http://localhost:9090`
   - Check application metrics: `http://localhost:8081/actuator/metrics`

## ğŸ”— Links Ãšteis

- [ğŸ“‹ DocumentaÃ§Ã£o Completa de Arquitetura](docs/DIAGRAMAS_ARQUITETURA_COMPLETOS.md)
- [ï¿½ Workflow de TrÃ¡fego de Mensagens](docs/WORKFLOW_TRAFEGO_MENSAGENS.md)
- [ğŸ“Š Diagramas do Workflow](docs/WORKFLOW_DIAGRAMAS_MERMAID.md)
- [ï¿½ğŸš€ Guia de Deploy Independente](docs/DEPLOYMENT_GUIDE.md)  
- [ğŸ—ï¸ Architecture Guide](docs/ARQUITETURA_HEXAGONAL.md)
- [ğŸ“Š Implementation Status](docs/HEXAGONAL_IMPLEMENTATION_STATUS.md)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spring Kafka Reference](https://spring.io/projects/spring-kafka)
- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)

---

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**ğŸš€ Built with Clean Architecture â€¢ Spring Boot â€¢ Apache Kafka â€¢ Kubernetes**

*Demonstrating enterprise-grade microservices patterns and practices*

</div>
- [Exemplo AMQ Streams](examples/amq-streams-example.md)
- [Monitoramento com Grafana](examples/monitoring/)

## ğŸ“– DocumentaÃ§Ã£o

- [ConfiguraÃ§Ã£o do Kafka](docs/kafka-setup.md)
- [Deploy no Kubernetes](docs/kubernetes-deployment.md)
- [PadrÃµes de Logs](docs/logging-patterns.md)
- [Monitoramento](docs/monitoring.md)
- [Troubleshooting](docs/troubleshooting.md)

## ğŸ¤ Contribuindo

Como este Ã© um projeto de estudos privado:

1. Use branches para diferentes experimentos (`git checkout -b experimento/nova-funcionalidade`)
2. FaÃ§a commits descritivos (`git commit -m 'Adiciona: novo padrÃ£o de processamento de logs'`)
3. Documente suas descobertas na pasta `docs/`
4. Crie issues para rastrear objetivos de aprendizado

## ğŸ“ Registro de Aprendizado

Mantenha um registro dos seus estudos:
- Crie arquivos `docs/experimento-YYYY-MM-DD.md` para documentar descobertas
- Use issues para rastrear objetivos e progresso
- Marque commits com tags para marcos importantes

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ“ Contato

Projeto criado para fins educacionais e estudos de Kafka e Kubernetes.

---

â­ Se este projeto te ajudou, deixe uma estrela no repositÃ³rio!
