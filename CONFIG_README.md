# ðŸš€ KBNT Enhanced Kafka Publication Logging System
## ConfiguraÃ§Ã£o Completa de Ambiente e Logs

### ðŸ“‹ VisÃ£o Geral do Sistema Completo

Este sistema implementa um workflow completo de publicaÃ§Ã£o e consumo de mensagens Kafka com logging avanÃ§ado e hash SHA-256 para rastreabilidade:

```
MicroserviÃ§o A (Producer) â†’ Red Hat AMQ Streams (Kafka) â†’ MicroserviÃ§o B (Consumer) â†’ PostgreSQL
```

### ðŸ—‚ï¸ Estrutura dos Arquivos de ConfiguraÃ§Ã£o

```
ðŸ“¦ config/
â”œâ”€â”€ ðŸ“„ startup.conf                    # ConfiguraÃ§Ã£o tÃ©cnica de timing e orquestraÃ§Ã£o
â”œâ”€â”€ ðŸ“„ logging-config.yaml             # ConfiguraÃ§Ã£o detalhada de logging para todos os componentes
â””â”€â”€ ðŸ“„ application-complete.yml        # ConfiguraÃ§Ã£o Spring Boot completa com profiles

ðŸ“¦ docs/
â””â”€â”€ ðŸ“„ STARTUP_CONFIGURATION_GUIDE.md  # Guia detalhado de tempos e troubleshooting

ðŸ“¦ scripts/
â”œâ”€â”€ ðŸ“„ start-complete-environment.sh   # Script de inicializaÃ§Ã£o para Linux/Mac
â”œâ”€â”€ ðŸ“„ start-complete-environment.ps1  # Script de inicializaÃ§Ã£o para Windows
â””â”€â”€ ðŸ“„ monitor-environment.sh          # Script de monitoramento e verificaÃ§Ã£o de status
```

### âš™ï¸ ConfiguraÃ§Ãµes Implementadas

#### 1. **ConfiguraÃ§Ã£o de Timing e OrquestraÃ§Ã£o** (`config/startup.conf`)
- â±ï¸ Tempos de inicializaÃ§Ã£o otimizados para cada componente
- ðŸ”„ ConfiguraÃ§Ã£o de dependÃªncias e ordem de startup
- ðŸ“Š ConfiguraÃ§Ãµes de recursos para desenvolvimento vs produÃ§Ã£o
- ðŸ”§ ParÃ¢metros de retry e timeouts

#### 2. **ConfiguraÃ§Ã£o de Logging Estruturado** (`config/logging-config.yaml`)
- ðŸ“ ConfiguraÃ§Ã£o detalhada para Producer e Consumer services
- ðŸŽ¯ Log levels especÃ­ficos por pacote e componente
- ðŸ“ˆ ConfiguraÃ§Ã£o de mÃ©tricas e monitoramento
- ðŸš¨ DefiniÃ§Ã£o de alertas e thresholds
- ðŸ”’ ConfiguraÃ§Ã£o de seguranÃ§a e compliance

#### 3. **ConfiguraÃ§Ã£o Spring Boot Completa** (`config/application-complete.yml`)
- ðŸŒ Profiles para development, testing, production, kubernetes
- ðŸ—„ï¸ ConfiguraÃ§Ã£o completa de PostgreSQL com pool de conexÃµes
- ðŸ”— ConfiguraÃ§Ã£o Kafka para producer e consumer
- ðŸ“¡ ConfiguraÃ§Ã£o Actuator e mÃ©tricas Prometheus
- âš¡ ConfiguraÃ§Ã£o de tarefas assÃ­ncronas e concorrÃªncia

### ðŸš¦ Tempos Estimados de InicializaÃ§Ã£o

| Componente | Tempo Estimado | ObservaÃ§Ãµes |
|------------|----------------|-------------|
| **Prerequisites Check** | ~30 segundos | VerificaÃ§Ã£o de kubectl, docker, maven |
| **PostgreSQL** | ~60 segundos | Banco de dados com inicializaÃ§Ã£o completa |
| **Red Hat AMQ Streams** | ~120 segundos | Cluster Kafka 3 brokers + Zookeeper |
| **Kafka Topics** | ~30 segundos | CriaÃ§Ã£o de 5 tÃ³picos com replicaÃ§Ã£o |
| **Producer Service** | ~90 segundos | Build + Deploy + Health checks |
| **Consumer Service** | ~90 segundos | Build + Deploy + Health checks |
| **Health Verification** | ~60 segundos | Testes de conectividade |
| **End-to-End Test** | ~60 segundos | Teste de workflow completo |

**â±ï¸ Tempo Total Estimado: 8-12 minutos** (primeira execuÃ§Ã£o pode levar atÃ© 15 minutos)

### ðŸŽ¯ Como Usar as ConfiguraÃ§Ãµes

#### 1. **InicializaÃ§Ã£o Completa do Ambiente**

**Linux/Mac:**
```bash
# InicializaÃ§Ã£o completa
./scripts/start-complete-environment.sh startup

# Com configuraÃ§Ãµes customizadas
NAMESPACE=kbnt-dev ./scripts/start-complete-environment.sh startup
```

**Windows:**
```powershell
# InicializaÃ§Ã£o completa
.\scripts\start-complete-environment.ps1 -Command startup

# Com parÃ¢metros customizados
.\scripts\start-complete-environment.ps1 -Command startup -Namespace "kbnt-dev" -Environment "development"
```

#### 2. **Monitoramento e VerificaÃ§Ã£o de Status**

```bash
# Monitoramento completo
./scripts/monitor-environment.sh full

# VerificaÃ§Ãµes especÃ­ficas
./scripts/monitor-environment.sh health
./scripts/monitor-environment.sh test
./scripts/monitor-environment.sh metrics
```

#### 3. **ConfiguraÃ§Ã£o das AplicaÃ§Ãµes Spring Boot**

As aplicaÃ§Ãµes usam o arquivo `config/application-complete.yml` como base:

```bash
# Para Producer Service
java -jar kbnt-stock-producer-service.jar --spring.config.location=config/application-complete.yml

# Para Consumer Service
java -jar kbnt-stock-consumer-service.jar --spring.config.location=config/application-complete.yml --spring.profiles.active=kubernetes
```

### ðŸ“Š Endpoints de Monitoramento DisponÃ­veis

#### **Producer Service** (porta 8080)
```
ðŸ¥ Health:     GET  /actuator/health
ðŸŽ¯ Readiness:  GET  /actuator/health/readiness
ðŸ“Š Metrics:    GET  /actuator/metrics
ðŸ”¥ Prometheus: GET  /actuator/prometheus
ðŸ“‹ Info:       GET  /actuator/info
ðŸ“¤ API:        POST /api/stock/update
```

#### **Consumer Service** (porta 8081)
```
ðŸ¥ Health:        GET  /api/consumer/actuator/health
ðŸŽ¯ Readiness:     GET  /api/consumer/actuator/health/readiness
ðŸ“Š Metrics:       GET  /api/consumer/actuator/metrics
ðŸ“ˆ Statistics:    GET  /api/consumer/monitoring/statistics
ðŸ“ Logs:          GET  /api/consumer/monitoring/logs
âŒ Errors:        GET  /api/consumer/monitoring/errors/api
âš¡ Performance:   GET  /api/consumer/monitoring/performance/slowest
```

### ðŸ” ConfiguraÃ§Ã£o de Logs por Componente

#### **NÃ­veis de Log Configurados:**
```yaml
Producer Service:
  com.estudoskbnt.kafka: INFO
  org.springframework.kafka: INFO
  org.apache.kafka: WARN

Consumer Service:
  com.estudoskbnt.consumer: INFO
  org.springframework.kafka: INFO
  org.hibernate.SQL: DEBUG (apenas development)

Kafka/AMQ Streams:
  kafka.root.logger.level: INFO
  kafka.controller: INFO
  kafka.producer: INFO
```

#### **PadrÃµes de Log:**
```
Console: "%clr(%d{HH:mm:ss.SSS}){faint} %clr([%X{correlationId:-}]){yellow} %clr(%-40.40logger{39}){cyan} - %m%n"
File:    "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{correlationId:-}] %logger{40} - %msg%n"
```

### ðŸŽ¨ Logs Estruturados com Campos Customizados

#### **Producer Service:**
- `correlationId` - ID de correlaÃ§Ã£o da requisiÃ§Ã£o
- `messageHash` - Hash SHA-256 da mensagem
- `kafkaTopic` - TÃ³pico Kafka de destino
- `kafkaPartition` - PartiÃ§Ã£o utilizada
- `kafkaOffset` - Offset da mensagem

#### **Consumer Service:**
- `correlationId` - ID de correlaÃ§Ã£o
- `messageId` - ID da mensagem processada
- `processingTimeMs` - Tempo de processamento
- `externalApiResponseTime` - Tempo da API externa
- `retryAttempt` - Tentativa de retry

### ðŸš¨ Alertas e MÃ©tricas Configurados

#### **Alertas de AplicaÃ§Ã£o:**
- Taxa de erro alta (> 5%)
- Falhas de envio Kafka (> 10 falhas)
- Tempo de resposta alto (P95 > 2000ms)
- Lag do consumer muito alto (> 1000 mensagens)

#### **Alertas de Infraestrutura:**
- Broker Kafka inativo
- Uso de disco alto (> 85%)
- Database inacessÃ­vel
- Uso alto de conexÃµes (> 80%)

### ðŸ”§ ConfiguraÃ§Ãµes EspecÃ­ficas por Ambiente

#### **Development:**
```yaml
- Kafka Brokers: 1
- Replicas de ServiÃ§o: 1
- Log Level: DEBUG
- SQL Logging: Habilitado
- MÃ©tricas Detalhadas: Habilitadas
```

#### **Production:**
```yaml
- Kafka Brokers: 3
- Replicas de ServiÃ§o: 2-3
- Log Level: INFO
- SQL Logging: Desabilitado
- Persistent Storage: Habilitado
```

### ðŸ“‹ Checklist de Sucesso

#### âœ… **Infraestrutura Pronta:**
- [ ] Cluster Kubernetes acessÃ­vel
- [ ] Namespace criado e configurado
- [ ] PostgreSQL rodando e pronto
- [ ] Cluster Kafka com status Ready
- [ ] Todos os 5 tÃ³picos criados

#### âœ… **ServiÃ§os Deployados:**
- [ ] Producer service rodando (2 replicas)
- [ ] Consumer service rodando (3 replicas)
- [ ] Todos os serviÃ§os passando health checks
- [ ] ServiÃ§os registrados no Kubernetes DNS

#### âœ… **Testes Funcionais:**
- [ ] Mensagem de teste enviada via Producer API
- [ ] Mensagem processada pelo Consumer
- [ ] Log de consumo criado no banco
- [ ] API de monitoramento retornando estatÃ­sticas

### ðŸ”„ Fluxo Completo de Dados

```mermaid
graph TD
    A[Cliente REST] --> B[Producer Service]
    B --> C[Hash SHA-256]
    C --> D[Kafka Topic]
    D --> E[Consumer Service]
    E --> F[External API]
    E --> G[PostgreSQL]
    G --> H[Logs de Auditoria]
    E --> I[MÃ©tricas Prometheus]
```

### ðŸ†˜ Troubleshooting Comum

#### **Kafka demorou mais que 5 minutos:**
```bash
# Verificar recursos do cluster
kubectl describe nodes

# Verificar logs do Strimzi
kubectl logs -n kbnt-system -l name=strimzi-cluster-operator
```

#### **Health checks falhando:**
```bash
# Verificar logs das aplicaÃ§Ãµes
kubectl logs -n kbnt-system -l app=kbnt-stock-producer-service

# Verificar conectividade Kafka
kubectl exec -it deployment/kbnt-stock-producer-service -n kbnt-system -- nc -zv kbnt-kafka-cluster-kafka-bootstrap 9092
```

#### **Teste end-to-end falhando:**
```bash
# Verificar tÃ³picos
kubectl get kafkatopics -n kbnt-system

# Verificar consumer group
kubectl exec -it kbnt-kafka-cluster-kafka-0 -n kbnt-system -- bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group kbnt-stock-consumer-group --describe
```

### ðŸ“ˆ OtimizaÃ§Ã£o de Performance

#### **Para Startup Mais RÃ¡pido (Dev):**
```bash
export KAFKA_BROKERS=1
export REPLICAS=1
export HEALTH_CHECK_INTERVAL=5s
```

#### **Para ProduÃ§Ã£o (Full Resilience):**
```bash
export KAFKA_BROKERS=3
export REPLICAS=3
export PERSISTENT_STORAGE=enabled
```

---

## ðŸŽ‰ Sistema Completo e Pronto!

O sistema estÃ¡ **100% completo** e inclui:

âœ… **Sistema Enhanced Kafka Publication Logging** com hash SHA-256  
âœ… **48 Testes UnitÃ¡rios Abrangentes** para validaÃ§Ã£o do Producer  
âœ… **Testes de Performance** para 100+ operaÃ§Ãµes concorrentes  
âœ… **Red Hat AMQ Streams** configurado para produÃ§Ã£o  
âœ… **MicroserviÃ§o B Consumer** completo com auditoria PostgreSQL  
âœ… **Testes de IntegraÃ§Ã£o End-to-End** com Testcontainers  
âœ… **Scripts de OrquestraÃ§Ã£o Completos** para Linux e Windows  
âœ… **Sistema de Monitoramento e Logs Estruturados**  
âœ… **ConfiguraÃ§Ãµes Detalhadas** para todos os ambientes  

### ðŸš€ Comandos para Iniciar:

**Linux/Mac:**
```bash
./scripts/start-complete-environment.sh startup
```

**Windows:**
```powershell
.\scripts\start-complete-environment.ps1 -Command startup
```

**Monitoramento:**
```bash
./scripts/monitor-environment.sh full
```

O ambiente estÃ¡ pronto para produÃ§Ã£o com logging estruturado, mÃ©tricas completas e timing otimizado! ðŸŽ¯
